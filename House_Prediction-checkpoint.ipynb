{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a7e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db36077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>121</td>\n",
       "      <td>14264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>121</td>\n",
       "      <td>12032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>13560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>128</td>\n",
       "      <td>12029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>122</td>\n",
       "      <td>14157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  age  distance  stores  latitude  longitude  price\n",
       "0  2009   21         9       6        84        121  14264\n",
       "1  2007    4         2       3        86        121  12032\n",
       "2  2016   18         3       7        90        120  13560\n",
       "3  2002   13         2       2        80        128  12029\n",
       "4  2014   25         5       8        81        122  14157"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('house_data.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a93c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>2007</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>13539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>129</td>\n",
       "      <td>14757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>14102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2010</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>128</td>\n",
       "      <td>14313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>12770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date  age  distance  stores  latitude  longitude  price\n",
       "4995  2007   17         6       3        90        125  13539\n",
       "4996  2016    7        10       0        85        129  14757\n",
       "4997  2017    6        10       5        90        125  14102\n",
       "4998  2010   37         3       5        81        128  14313\n",
       "4999  2018    9         1       9        90        127  12770"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7b4aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd852cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   age        5000 non-null   int64\n",
      " 1   distance   5000 non-null   int64\n",
      " 2   stores     5000 non-null   int64\n",
      " 3   latitude   5000 non-null   int64\n",
      " 4   longitude  5000 non-null   int64\n",
      " 5   price      5000 non-null   int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 234.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9f509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a39a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(\"price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d4318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30afea88",
   "metadata": {},
   "source": [
    "# Checking the Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d98c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date    age  distance  stores  latitude  longitude  price\n",
       "0     False  False     False   False     False      False  False\n",
       "1     False  False     False   False     False      False  False\n",
       "2     False  False     False   False     False      False  False\n",
       "3     False  False     False   False     False      False  False\n",
       "4     False  False     False   False     False      False  False\n",
       "...     ...    ...       ...     ...       ...        ...    ...\n",
       "4995  False  False     False   False     False      False  False\n",
       "4996  False  False     False   False     False      False  False\n",
       "4997  False  False     False   False     False      False  False\n",
       "4998  False  False     False   False     False      False  False\n",
       "4999  False  False     False   False     False      False  False\n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e615c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date         0\n",
       "age          0\n",
       "distance     0\n",
       "stores       0\n",
       "latitude     0\n",
       "longitude    0\n",
       "price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375f9e4",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1240ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181384</td>\n",
       "      <td>1.257002</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>-0.307212</td>\n",
       "      <td>-1.260799</td>\n",
       "      <td>0.350088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.319118</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.609312</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>-1.260799</td>\n",
       "      <td>-1.836486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.083410</td>\n",
       "      <td>-0.618094</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>1.590328</td>\n",
       "      <td>-1.576456</td>\n",
       "      <td>-0.339584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.524735</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.927491</td>\n",
       "      <td>-1.572238</td>\n",
       "      <td>0.948803</td>\n",
       "      <td>-1.839425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.981581</td>\n",
       "      <td>-1.255981</td>\n",
       "      <td>-0.945141</td>\n",
       "      <td>0.245266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  distance    stores  latitude  longitude     price\n",
       "0  0.181384  1.257002  0.345224 -0.307212  -1.260799  0.350088\n",
       "1 -1.319118 -0.930610 -0.609312  0.325301  -1.260799 -1.836486\n",
       "2 -0.083410 -0.618094  0.663402  1.590328  -1.576456 -0.339584\n",
       "3 -0.524735 -0.930610 -0.927491 -1.572238   0.948803 -1.839425\n",
       "4  0.534444  0.006938  0.981581 -1.255981  -0.945141  0.245266"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,1:]\n",
    "df_norm = (df - df.mean()) / df.std()\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e39125",
   "metadata": {},
   "source": [
    "# Selecting the X-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efbda68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>distance</th>\n",
       "      <th>stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181384</td>\n",
       "      <td>1.257002</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>-0.307212</td>\n",
       "      <td>-1.260799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.319118</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.609312</td>\n",
       "      <td>0.325301</td>\n",
       "      <td>-1.260799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.083410</td>\n",
       "      <td>-0.618094</td>\n",
       "      <td>0.663402</td>\n",
       "      <td>1.590328</td>\n",
       "      <td>-1.576456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.524735</td>\n",
       "      <td>-0.930610</td>\n",
       "      <td>-0.927491</td>\n",
       "      <td>-1.572238</td>\n",
       "      <td>0.948803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.981581</td>\n",
       "      <td>-1.255981</td>\n",
       "      <td>-0.945141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  distance    stores  latitude  longitude\n",
       "0  0.181384  1.257002  0.345224 -0.307212  -1.260799\n",
       "1 -1.319118 -0.930610 -0.609312  0.325301  -1.260799\n",
       "2 -0.083410 -0.618094  0.663402  1.590328  -1.576456\n",
       "3 -0.524735 -0.930610 -0.927491 -1.572238   0.948803\n",
       "4  0.534444  0.006938  0.981581 -1.255981  -0.945141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_norm.iloc[:, :5]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5da3a",
   "metadata": {},
   "source": [
    "# Selecting the Y-Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd289b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.350088\n",
       "1   -1.836486\n",
       "2   -0.339584\n",
       "3   -1.839425\n",
       "4    0.245266\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df_norm.iloc[:, -1]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1a635",
   "metadata": {},
   "source": [
    "# Feature and Label Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c019627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = X.values\n",
    "Y_arr = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac9f326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18138426,  1.25700164,  0.34522379, -0.30721158, -1.26079862],\n",
       "       [-1.31911814, -0.93060999, -0.60931203,  0.32530146, -1.26079862],\n",
       "       [-0.08341028, -0.61809404,  0.66340239,  1.59032754, -1.57645598],\n",
       "       ...,\n",
       "       [-1.14258845,  1.56951759,  0.02704518,  1.59032754,  0.00183081],\n",
       "       [ 1.59362182, -0.61809404,  0.02704518, -1.25598114,  0.94880289],\n",
       "       [-0.87779391, -1.24312594,  1.2997596 ,  1.59032754,  0.63314553]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84bdba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35008836, -1.83648583, -0.33958379, ...,  0.19138539,\n",
       "        0.39809111, -1.11350566])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bd50e",
   "metadata": {},
   "source": [
    "# Testing and Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fc0e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4950, 5)\n",
      "y_train shape:  (4950,)\n",
      "X_test shape:  (50, 5)\n",
      "y_test shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_arr, Y_arr, test_size = 0.01, shuffle = True, random_state=1)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e612c",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f1c45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(10, input_shape = (5,), activation = 'relu'),\n",
    "        Dense(20, activation = 'relu'),\n",
    "        Dense(5, activation = 'relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer='adadelta'\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5334460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 105       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 391\n",
      "Trainable params: 391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64f11794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "preds_on_untrained = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91089418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "155/155 [==============================] - 1s 3ms/step - loss: 1.0258 - val_loss: 0.6898\n",
      "Epoch 2/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0252 - val_loss: 0.6894\n",
      "Epoch 3/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0246 - val_loss: 0.6889\n",
      "Epoch 4/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 1.0240 - val_loss: 0.6885\n",
      "Epoch 5/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0234 - val_loss: 0.6881\n",
      "Epoch 6/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0228 - val_loss: 0.6877\n",
      "Epoch 7/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0222 - val_loss: 0.6873\n",
      "Epoch 8/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0216 - val_loss: 0.6869\n",
      "Epoch 9/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0210 - val_loss: 0.6865\n",
      "Epoch 10/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0204 - val_loss: 0.6861\n",
      "Epoch 11/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 1.0199 - val_loss: 0.6857\n",
      "Epoch 12/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0193 - val_loss: 0.6853\n",
      "Epoch 13/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0187 - val_loss: 0.6849\n",
      "Epoch 14/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0181 - val_loss: 0.6845\n",
      "Epoch 15/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 1.0176 - val_loss: 0.6841\n",
      "Epoch 16/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 1.0170 - val_loss: 0.6837\n",
      "Epoch 17/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0164 - val_loss: 0.6833\n",
      "Epoch 18/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0158 - val_loss: 0.6828\n",
      "Epoch 19/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0153 - val_loss: 0.6824\n",
      "Epoch 20/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0147 - val_loss: 0.6820\n",
      "Epoch 21/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0141 - val_loss: 0.6817\n",
      "Epoch 22/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0136 - val_loss: 0.6813\n",
      "Epoch 23/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0130 - val_loss: 0.6809\n",
      "Epoch 24/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0124 - val_loss: 0.6805\n",
      "Epoch 25/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0119 - val_loss: 0.6801\n",
      "Epoch 26/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0113 - val_loss: 0.6797\n",
      "Epoch 27/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0108 - val_loss: 0.6793\n",
      "Epoch 28/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 1.0102 - val_loss: 0.6789\n",
      "Epoch 29/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0096 - val_loss: 0.6785\n",
      "Epoch 30/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0091 - val_loss: 0.6781\n",
      "Epoch 31/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0085 - val_loss: 0.6777\n",
      "Epoch 32/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0080 - val_loss: 0.6774\n",
      "Epoch 33/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0074 - val_loss: 0.6770\n",
      "Epoch 34/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0069 - val_loss: 0.6766\n",
      "Epoch 35/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0063 - val_loss: 0.6762\n",
      "Epoch 36/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0058 - val_loss: 0.6758\n",
      "Epoch 37/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0052 - val_loss: 0.6754\n",
      "Epoch 38/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0047 - val_loss: 0.6750\n",
      "Epoch 39/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0042 - val_loss: 0.6747\n",
      "Epoch 40/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0037 - val_loss: 0.6743\n",
      "Epoch 41/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0031 - val_loss: 0.6739\n",
      "Epoch 42/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0026 - val_loss: 0.6736\n",
      "Epoch 43/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0021 - val_loss: 0.6732\n",
      "Epoch 44/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0016 - val_loss: 0.6728\n",
      "Epoch 45/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0011 - val_loss: 0.6725\n",
      "Epoch 46/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0006 - val_loss: 0.6721\n",
      "Epoch 47/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 1.0001 - val_loss: 0.6717\n",
      "Epoch 48/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9996 - val_loss: 0.6714\n",
      "Epoch 49/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9990 - val_loss: 0.6710\n",
      "Epoch 50/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9985 - val_loss: 0.6706\n",
      "Epoch 51/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9980 - val_loss: 0.6703\n",
      "Epoch 52/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9975 - val_loss: 0.6699\n",
      "Epoch 53/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9970 - val_loss: 0.6695\n",
      "Epoch 54/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9965 - val_loss: 0.6692\n",
      "Epoch 55/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9960 - val_loss: 0.6688\n",
      "Epoch 56/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9954 - val_loss: 0.6685\n",
      "Epoch 57/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9949 - val_loss: 0.6681\n",
      "Epoch 58/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9944 - val_loss: 0.6677\n",
      "Epoch 59/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9939 - val_loss: 0.6674\n",
      "Epoch 60/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9934 - val_loss: 0.6670\n",
      "Epoch 61/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9928 - val_loss: 0.6666\n",
      "Epoch 62/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9923 - val_loss: 0.6663\n",
      "Epoch 63/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9918 - val_loss: 0.6659\n",
      "Epoch 64/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9913 - val_loss: 0.6655\n",
      "Epoch 65/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 0.6652\n",
      "Epoch 66/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9903 - val_loss: 0.6648\n",
      "Epoch 67/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9898 - val_loss: 0.6645\n",
      "Epoch 68/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9893 - val_loss: 0.6641\n",
      "Epoch 69/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9888 - val_loss: 0.6638\n",
      "Epoch 70/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9883 - val_loss: 0.6634\n",
      "Epoch 71/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9878 - val_loss: 0.6631\n",
      "Epoch 72/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9873 - val_loss: 0.6627\n",
      "Epoch 73/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9868 - val_loss: 0.6624\n",
      "Epoch 74/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9863 - val_loss: 0.6620\n",
      "Epoch 75/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9857 - val_loss: 0.6617\n",
      "Epoch 76/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9852 - val_loss: 0.6613\n",
      "Epoch 77/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9847 - val_loss: 0.6609\n",
      "Epoch 78/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9842 - val_loss: 0.6606\n",
      "Epoch 79/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9837 - val_loss: 0.6602\n",
      "Epoch 80/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9832 - val_loss: 0.6599\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9827 - val_loss: 0.6595\n",
      "Epoch 82/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9822 - val_loss: 0.6592\n",
      "Epoch 83/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9816 - val_loss: 0.6588\n",
      "Epoch 84/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9811 - val_loss: 0.6585\n",
      "Epoch 85/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9806 - val_loss: 0.6581\n",
      "Epoch 86/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9801 - val_loss: 0.6578\n",
      "Epoch 87/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9796 - val_loss: 0.6574\n",
      "Epoch 88/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9791 - val_loss: 0.6571\n",
      "Epoch 89/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9786 - val_loss: 0.6567\n",
      "Epoch 90/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9781 - val_loss: 0.6564\n",
      "Epoch 91/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9776 - val_loss: 0.6560\n",
      "Epoch 92/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9771 - val_loss: 0.6557\n",
      "Epoch 93/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9766 - val_loss: 0.6553\n",
      "Epoch 94/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9761 - val_loss: 0.6550\n",
      "Epoch 95/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9756 - val_loss: 0.6546\n",
      "Epoch 96/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9751 - val_loss: 0.6543\n",
      "Epoch 97/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9746 - val_loss: 0.6539\n",
      "Epoch 98/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.6536\n",
      "Epoch 99/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9736 - val_loss: 0.6533\n",
      "Epoch 100/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9731 - val_loss: 0.6529\n",
      "Epoch 101/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9726 - val_loss: 0.6526\n",
      "Epoch 102/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9721 - val_loss: 0.6522\n",
      "Epoch 103/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9716 - val_loss: 0.6519\n",
      "Epoch 104/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9711 - val_loss: 0.6515\n",
      "Epoch 105/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9706 - val_loss: 0.6512\n",
      "Epoch 106/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9701 - val_loss: 0.6508\n",
      "Epoch 107/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9696 - val_loss: 0.6505\n",
      "Epoch 108/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9691 - val_loss: 0.6501\n",
      "Epoch 109/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.6498\n",
      "Epoch 110/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9680 - val_loss: 0.6494\n",
      "Epoch 111/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9675 - val_loss: 0.6491\n",
      "Epoch 112/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9670 - val_loss: 0.6487\n",
      "Epoch 113/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9665 - val_loss: 0.6484\n",
      "Epoch 114/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9660 - val_loss: 0.6480\n",
      "Epoch 115/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9655 - val_loss: 0.6477\n",
      "Epoch 116/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9650 - val_loss: 0.6473\n",
      "Epoch 117/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9645 - val_loss: 0.6470\n",
      "Epoch 118/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9640 - val_loss: 0.6466\n",
      "Epoch 119/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9635 - val_loss: 0.6463\n",
      "Epoch 120/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9630 - val_loss: 0.6459\n",
      "Epoch 121/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9625 - val_loss: 0.6456\n",
      "Epoch 122/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9619 - val_loss: 0.6452\n",
      "Epoch 123/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9614 - val_loss: 0.6449\n",
      "Epoch 124/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9609 - val_loss: 0.6445\n",
      "Epoch 125/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9604 - val_loss: 0.6442\n",
      "Epoch 126/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9599 - val_loss: 0.6438\n",
      "Epoch 127/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9593 - val_loss: 0.6434\n",
      "Epoch 128/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9588 - val_loss: 0.6431\n",
      "Epoch 129/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9583 - val_loss: 0.6427\n",
      "Epoch 130/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9578 - val_loss: 0.6424\n",
      "Epoch 131/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9572 - val_loss: 0.6420\n",
      "Epoch 132/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9567 - val_loss: 0.6417\n",
      "Epoch 133/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9562 - val_loss: 0.6413\n",
      "Epoch 134/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9557 - val_loss: 0.6410\n",
      "Epoch 135/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9552 - val_loss: 0.6406\n",
      "Epoch 136/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9547 - val_loss: 0.6403\n",
      "Epoch 137/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9541 - val_loss: 0.6399\n",
      "Epoch 138/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9536 - val_loss: 0.6395\n",
      "Epoch 139/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9530 - val_loss: 0.6392\n",
      "Epoch 140/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9525 - val_loss: 0.6388\n",
      "Epoch 141/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9520 - val_loss: 0.6385\n",
      "Epoch 142/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9514 - val_loss: 0.6381\n",
      "Epoch 143/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9509 - val_loss: 0.6378\n",
      "Epoch 144/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9504 - val_loss: 0.6374\n",
      "Epoch 145/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9498 - val_loss: 0.6370\n",
      "Epoch 146/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9493 - val_loss: 0.6367\n",
      "Epoch 147/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9487 - val_loss: 0.6363\n",
      "Epoch 148/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9481 - val_loss: 0.6360\n",
      "Epoch 149/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9476 - val_loss: 0.6356\n",
      "Epoch 150/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9470 - val_loss: 0.6353\n",
      "Epoch 151/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9465 - val_loss: 0.6349\n",
      "Epoch 152/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9459 - val_loss: 0.6346\n",
      "Epoch 153/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9454 - val_loss: 0.6342\n",
      "Epoch 154/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9448 - val_loss: 0.6339\n",
      "Epoch 155/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9443 - val_loss: 0.6336\n",
      "Epoch 156/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9437 - val_loss: 0.6332\n",
      "Epoch 157/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9432 - val_loss: 0.6329\n",
      "Epoch 158/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 0.6326\n",
      "Epoch 159/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9421 - val_loss: 0.6322\n",
      "Epoch 160/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9415 - val_loss: 0.6319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9410 - val_loss: 0.6316\n",
      "Epoch 162/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9404 - val_loss: 0.6312\n",
      "Epoch 163/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 0.6309\n",
      "Epoch 164/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9393 - val_loss: 0.6305\n",
      "Epoch 165/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9387 - val_loss: 0.6302\n",
      "Epoch 166/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9382 - val_loss: 0.6298\n",
      "Epoch 167/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9376 - val_loss: 0.6295\n",
      "Epoch 168/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 0.6292\n",
      "Epoch 169/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9364 - val_loss: 0.6288\n",
      "Epoch 170/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9358 - val_loss: 0.6285\n",
      "Epoch 171/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9353 - val_loss: 0.6281\n",
      "Epoch 172/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9347 - val_loss: 0.6278\n",
      "Epoch 173/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9341 - val_loss: 0.6274\n",
      "Epoch 174/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9335 - val_loss: 0.6271\n",
      "Epoch 175/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9329 - val_loss: 0.6268\n",
      "Epoch 176/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9324 - val_loss: 0.6264\n",
      "Epoch 177/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9318 - val_loss: 0.6260\n",
      "Epoch 178/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9312 - val_loss: 0.6257\n",
      "Epoch 179/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9306 - val_loss: 0.6253\n",
      "Epoch 180/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9300 - val_loss: 0.6249\n",
      "Epoch 181/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9294 - val_loss: 0.6246\n",
      "Epoch 182/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9288 - val_loss: 0.6242\n",
      "Epoch 183/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9282 - val_loss: 0.6238\n",
      "Epoch 184/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9276 - val_loss: 0.6235\n",
      "Epoch 185/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9271 - val_loss: 0.6231\n",
      "Epoch 186/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9265 - val_loss: 0.6228\n",
      "Epoch 187/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9259 - val_loss: 0.6224\n",
      "Epoch 188/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.6220\n",
      "Epoch 189/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9247 - val_loss: 0.6217\n",
      "Epoch 190/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9241 - val_loss: 0.6213\n",
      "Epoch 191/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9235 - val_loss: 0.6210\n",
      "Epoch 192/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9229 - val_loss: 0.6206\n",
      "Epoch 193/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9223 - val_loss: 0.6202\n",
      "Epoch 194/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9217 - val_loss: 0.6199\n",
      "Epoch 195/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9211 - val_loss: 0.6195\n",
      "Epoch 196/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9205 - val_loss: 0.6191\n",
      "Epoch 197/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9199 - val_loss: 0.6188\n",
      "Epoch 198/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 0.6184\n",
      "Epoch 199/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9187 - val_loss: 0.6181\n",
      "Epoch 200/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9181 - val_loss: 0.6177\n",
      "Epoch 201/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9175 - val_loss: 0.6173\n",
      "Epoch 202/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9169 - val_loss: 0.6170\n",
      "Epoch 203/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 0.6166\n",
      "Epoch 204/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9156 - val_loss: 0.6162\n",
      "Epoch 205/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 0.6158\n",
      "Epoch 206/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9144 - val_loss: 0.6155\n",
      "Epoch 207/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9138 - val_loss: 0.6151\n",
      "Epoch 208/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9132 - val_loss: 0.6147\n",
      "Epoch 209/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9125 - val_loss: 0.6144\n",
      "Epoch 210/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9119 - val_loss: 0.6140\n",
      "Epoch 211/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9113 - val_loss: 0.6137\n",
      "Epoch 212/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9107 - val_loss: 0.6133\n",
      "Epoch 213/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9101 - val_loss: 0.6129\n",
      "Epoch 214/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9094 - val_loss: 0.6126\n",
      "Epoch 215/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9088 - val_loss: 0.6122\n",
      "Epoch 216/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9082 - val_loss: 0.6118\n",
      "Epoch 217/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9076 - val_loss: 0.6115\n",
      "Epoch 218/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9069 - val_loss: 0.6111\n",
      "Epoch 219/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.9063 - val_loss: 0.6107\n",
      "Epoch 220/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9057 - val_loss: 0.6104\n",
      "Epoch 221/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9050 - val_loss: 0.6100\n",
      "Epoch 222/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9044 - val_loss: 0.6096\n",
      "Epoch 223/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9038 - val_loss: 0.6092\n",
      "Epoch 224/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9031 - val_loss: 0.6089\n",
      "Epoch 225/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9025 - val_loss: 0.6085\n",
      "Epoch 226/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9019 - val_loss: 0.6081\n",
      "Epoch 227/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9012 - val_loss: 0.6077\n",
      "Epoch 228/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.9006 - val_loss: 0.6074\n",
      "Epoch 229/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8999 - val_loss: 0.6070\n",
      "Epoch 230/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8993 - val_loss: 0.6066\n",
      "Epoch 231/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8986 - val_loss: 0.6063\n",
      "Epoch 232/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8980 - val_loss: 0.6059\n",
      "Epoch 233/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 0.6055\n",
      "Epoch 234/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8967 - val_loss: 0.6052\n",
      "Epoch 235/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8961 - val_loss: 0.6048\n",
      "Epoch 236/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8955 - val_loss: 0.6045\n",
      "Epoch 237/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8948 - val_loss: 0.6041\n",
      "Epoch 238/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8942 - val_loss: 0.6037\n",
      "Epoch 239/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8936 - val_loss: 0.6034\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8929 - val_loss: 0.6030\n",
      "Epoch 241/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8923 - val_loss: 0.6026\n",
      "Epoch 242/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8916 - val_loss: 0.6023\n",
      "Epoch 243/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8910 - val_loss: 0.6019\n",
      "Epoch 244/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8903 - val_loss: 0.6015\n",
      "Epoch 245/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8896 - val_loss: 0.6011\n",
      "Epoch 246/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8890 - val_loss: 0.6007\n",
      "Epoch 247/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8883 - val_loss: 0.6004\n",
      "Epoch 248/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8876 - val_loss: 0.6000\n",
      "Epoch 249/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8870 - val_loss: 0.5996\n",
      "Epoch 250/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8863 - val_loss: 0.5992\n",
      "Epoch 251/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8856 - val_loss: 0.5988\n",
      "Epoch 252/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8849 - val_loss: 0.5984\n",
      "Epoch 253/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8843 - val_loss: 0.5981\n",
      "Epoch 254/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8836 - val_loss: 0.5977\n",
      "Epoch 255/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8829 - val_loss: 0.5973\n",
      "Epoch 256/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8823 - val_loss: 0.5969\n",
      "Epoch 257/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8816 - val_loss: 0.5965\n",
      "Epoch 258/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8810 - val_loss: 0.5962\n",
      "Epoch 259/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8803 - val_loss: 0.5958\n",
      "Epoch 260/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8796 - val_loss: 0.5954\n",
      "Epoch 261/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8790 - val_loss: 0.5950\n",
      "Epoch 262/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8783 - val_loss: 0.5947\n",
      "Epoch 263/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8776 - val_loss: 0.5943\n",
      "Epoch 264/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8770 - val_loss: 0.5939\n",
      "Epoch 265/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8763 - val_loss: 0.5935\n",
      "Epoch 266/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8756 - val_loss: 0.5931\n",
      "Epoch 267/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8749 - val_loss: 0.5928\n",
      "Epoch 268/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8742 - val_loss: 0.5924\n",
      "Epoch 269/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8736 - val_loss: 0.5920\n",
      "Epoch 270/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8729 - val_loss: 0.5916\n",
      "Epoch 271/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8722 - val_loss: 0.5912\n",
      "Epoch 272/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8715 - val_loss: 0.5908\n",
      "Epoch 273/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8709 - val_loss: 0.5905\n",
      "Epoch 274/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8702 - val_loss: 0.5901\n",
      "Epoch 275/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8695 - val_loss: 0.5897\n",
      "Epoch 276/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8688 - val_loss: 0.5893\n",
      "Epoch 277/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8682 - val_loss: 0.5889\n",
      "Epoch 278/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8675 - val_loss: 0.5886\n",
      "Epoch 279/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8668 - val_loss: 0.5882\n",
      "Epoch 280/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8661 - val_loss: 0.5878\n",
      "Epoch 281/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8655 - val_loss: 0.5874\n",
      "Epoch 282/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8648 - val_loss: 0.5870\n",
      "Epoch 283/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8641 - val_loss: 0.5866\n",
      "Epoch 284/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8634 - val_loss: 0.5862\n",
      "Epoch 285/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8627 - val_loss: 0.5858\n",
      "Epoch 286/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8620 - val_loss: 0.5855\n",
      "Epoch 287/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8614 - val_loss: 0.5851\n",
      "Epoch 288/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8607 - val_loss: 0.5847\n",
      "Epoch 289/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8600 - val_loss: 0.5843\n",
      "Epoch 290/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8593 - val_loss: 0.5839\n",
      "Epoch 291/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8587 - val_loss: 0.5835\n",
      "Epoch 292/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8580 - val_loss: 0.5832\n",
      "Epoch 293/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8573 - val_loss: 0.5828\n",
      "Epoch 294/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8566 - val_loss: 0.5824\n",
      "Epoch 295/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8559 - val_loss: 0.5820\n",
      "Epoch 296/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8552 - val_loss: 0.5816\n",
      "Epoch 297/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8545 - val_loss: 0.5812\n",
      "Epoch 298/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8538 - val_loss: 0.5808\n",
      "Epoch 299/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8532 - val_loss: 0.5805\n",
      "Epoch 300/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8525 - val_loss: 0.5801\n",
      "Epoch 301/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8517 - val_loss: 0.5797\n",
      "Epoch 302/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8510 - val_loss: 0.5793\n",
      "Epoch 303/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8503 - val_loss: 0.5789\n",
      "Epoch 304/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8496 - val_loss: 0.5785\n",
      "Epoch 305/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8489 - val_loss: 0.5781\n",
      "Epoch 306/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8482 - val_loss: 0.5777\n",
      "Epoch 307/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8475 - val_loss: 0.5773\n",
      "Epoch 308/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8468 - val_loss: 0.5769\n",
      "Epoch 309/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8461 - val_loss: 0.5766\n",
      "Epoch 310/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8454 - val_loss: 0.5762\n",
      "Epoch 311/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8447 - val_loss: 0.5758\n",
      "Epoch 312/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8440 - val_loss: 0.5754\n",
      "Epoch 313/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8433 - val_loss: 0.5750\n",
      "Epoch 314/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8426 - val_loss: 0.5746\n",
      "Epoch 315/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8419 - val_loss: 0.5742\n",
      "Epoch 316/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8412 - val_loss: 0.5738\n",
      "Epoch 317/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8405 - val_loss: 0.5735\n",
      "Epoch 318/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8398 - val_loss: 0.5731\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8390 - val_loss: 0.5727\n",
      "Epoch 320/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8383 - val_loss: 0.5723\n",
      "Epoch 321/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8376 - val_loss: 0.5719\n",
      "Epoch 322/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8369 - val_loss: 0.5715\n",
      "Epoch 323/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8362 - val_loss: 0.5711\n",
      "Epoch 324/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8355 - val_loss: 0.5707\n",
      "Epoch 325/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8347 - val_loss: 0.5703\n",
      "Epoch 326/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8340 - val_loss: 0.5699\n",
      "Epoch 327/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8332 - val_loss: 0.5695\n",
      "Epoch 328/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8325 - val_loss: 0.5691\n",
      "Epoch 329/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8318 - val_loss: 0.5687\n",
      "Epoch 330/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8311 - val_loss: 0.5683\n",
      "Epoch 331/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.8304 - val_loss: 0.5679\n",
      "Epoch 332/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8296 - val_loss: 0.5675\n",
      "Epoch 333/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8289 - val_loss: 0.5671\n",
      "Epoch 334/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8282 - val_loss: 0.5667\n",
      "Epoch 335/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8275 - val_loss: 0.5663\n",
      "Epoch 336/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8268 - val_loss: 0.5660\n",
      "Epoch 337/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8261 - val_loss: 0.5656\n",
      "Epoch 338/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8254 - val_loss: 0.5652\n",
      "Epoch 339/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8247 - val_loss: 0.5648\n",
      "Epoch 340/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8240 - val_loss: 0.5644\n",
      "Epoch 341/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8233 - val_loss: 0.5640\n",
      "Epoch 342/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8226 - val_loss: 0.5636\n",
      "Epoch 343/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8219 - val_loss: 0.5632\n",
      "Epoch 344/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8212 - val_loss: 0.5629\n",
      "Epoch 345/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8205 - val_loss: 0.5625\n",
      "Epoch 346/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8198 - val_loss: 0.5621\n",
      "Epoch 347/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8190 - val_loss: 0.5617\n",
      "Epoch 348/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8183 - val_loss: 0.5613\n",
      "Epoch 349/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8176 - val_loss: 0.5609\n",
      "Epoch 350/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8169 - val_loss: 0.5605\n",
      "Epoch 351/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8162 - val_loss: 0.5602\n",
      "Epoch 352/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8155 - val_loss: 0.5598\n",
      "Epoch 353/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8148 - val_loss: 0.5594\n",
      "Epoch 354/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8141 - val_loss: 0.5590\n",
      "Epoch 355/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8133 - val_loss: 0.5586\n",
      "Epoch 356/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8126 - val_loss: 0.5582\n",
      "Epoch 357/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8119 - val_loss: 0.5578\n",
      "Epoch 358/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8112 - val_loss: 0.5574\n",
      "Epoch 359/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8104 - val_loss: 0.5570\n",
      "Epoch 360/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8097 - val_loss: 0.5566\n",
      "Epoch 361/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8090 - val_loss: 0.5562\n",
      "Epoch 362/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8082 - val_loss: 0.5558\n",
      "Epoch 363/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8075 - val_loss: 0.5554\n",
      "Epoch 364/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8067 - val_loss: 0.5550\n",
      "Epoch 365/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8060 - val_loss: 0.5546\n",
      "Epoch 366/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8053 - val_loss: 0.5542\n",
      "Epoch 367/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8045 - val_loss: 0.5538\n",
      "Epoch 368/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8038 - val_loss: 0.5534\n",
      "Epoch 369/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8031 - val_loss: 0.5530\n",
      "Epoch 370/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8023 - val_loss: 0.5526\n",
      "Epoch 371/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8016 - val_loss: 0.5522\n",
      "Epoch 372/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8009 - val_loss: 0.5518\n",
      "Epoch 373/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.8002 - val_loss: 0.5514\n",
      "Epoch 374/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7994 - val_loss: 0.5510\n",
      "Epoch 375/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7987 - val_loss: 0.5506\n",
      "Epoch 376/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7980 - val_loss: 0.5502\n",
      "Epoch 377/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7972 - val_loss: 0.5498\n",
      "Epoch 378/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7965 - val_loss: 0.5494\n",
      "Epoch 379/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7957 - val_loss: 0.5489\n",
      "Epoch 380/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7950 - val_loss: 0.5485\n",
      "Epoch 381/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7943 - val_loss: 0.5481\n",
      "Epoch 382/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7935 - val_loss: 0.5477\n",
      "Epoch 383/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7928 - val_loss: 0.5473\n",
      "Epoch 384/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7921 - val_loss: 0.5469\n",
      "Epoch 385/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7913 - val_loss: 0.5465\n",
      "Epoch 386/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7906 - val_loss: 0.5461\n",
      "Epoch 387/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7899 - val_loss: 0.5458\n",
      "Epoch 388/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7892 - val_loss: 0.5454\n",
      "Epoch 389/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7885 - val_loss: 0.5450\n",
      "Epoch 390/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7878 - val_loss: 0.5446\n",
      "Epoch 391/500\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.7871 - val_loss: 0.5442\n",
      "Epoch 392/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7863 - val_loss: 0.5438\n",
      "Epoch 393/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7856 - val_loss: 0.5434\n",
      "Epoch 394/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7849 - val_loss: 0.5430\n",
      "Epoch 395/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7841 - val_loss: 0.5426\n",
      "Epoch 396/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7834 - val_loss: 0.5422\n",
      "Epoch 397/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7826 - val_loss: 0.5418\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7818 - val_loss: 0.5414\n",
      "Epoch 399/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7811 - val_loss: 0.5410\n",
      "Epoch 400/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7803 - val_loss: 0.5406\n",
      "Epoch 401/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7796 - val_loss: 0.5401\n",
      "Epoch 402/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7788 - val_loss: 0.5397\n",
      "Epoch 403/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7781 - val_loss: 0.5393\n",
      "Epoch 404/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7773 - val_loss: 0.5389\n",
      "Epoch 405/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7766 - val_loss: 0.5385\n",
      "Epoch 406/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7759 - val_loss: 0.5381\n",
      "Epoch 407/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7752 - val_loss: 0.5377\n",
      "Epoch 408/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7744 - val_loss: 0.5373\n",
      "Epoch 409/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7737 - val_loss: 0.5369\n",
      "Epoch 410/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7730 - val_loss: 0.5365\n",
      "Epoch 411/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7722 - val_loss: 0.5361\n",
      "Epoch 412/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7715 - val_loss: 0.5357\n",
      "Epoch 413/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7708 - val_loss: 0.5353\n",
      "Epoch 414/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7700 - val_loss: 0.5349\n",
      "Epoch 415/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7693 - val_loss: 0.5345\n",
      "Epoch 416/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7686 - val_loss: 0.5341\n",
      "Epoch 417/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7678 - val_loss: 0.5337\n",
      "Epoch 418/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7671 - val_loss: 0.5333\n",
      "Epoch 419/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7663 - val_loss: 0.5329\n",
      "Epoch 420/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7656 - val_loss: 0.5324\n",
      "Epoch 421/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7648 - val_loss: 0.5320\n",
      "Epoch 422/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7641 - val_loss: 0.5316\n",
      "Epoch 423/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7633 - val_loss: 0.5312\n",
      "Epoch 424/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7626 - val_loss: 0.5308\n",
      "Epoch 425/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7618 - val_loss: 0.5304\n",
      "Epoch 426/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7611 - val_loss: 0.5300\n",
      "Epoch 427/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7604 - val_loss: 0.5296\n",
      "Epoch 428/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7596 - val_loss: 0.5292\n",
      "Epoch 429/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7589 - val_loss: 0.5288\n",
      "Epoch 430/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7582 - val_loss: 0.5284\n",
      "Epoch 431/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7574 - val_loss: 0.5281\n",
      "Epoch 432/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7567 - val_loss: 0.5277\n",
      "Epoch 433/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7560 - val_loss: 0.5273\n",
      "Epoch 434/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7553 - val_loss: 0.5269\n",
      "Epoch 435/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7546 - val_loss: 0.5266\n",
      "Epoch 436/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7539 - val_loss: 0.5262\n",
      "Epoch 437/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7531 - val_loss: 0.5258\n",
      "Epoch 438/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7524 - val_loss: 0.5254\n",
      "Epoch 439/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7517 - val_loss: 0.5250\n",
      "Epoch 440/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7510 - val_loss: 0.5246\n",
      "Epoch 441/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7503 - val_loss: 0.5242\n",
      "Epoch 442/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7495 - val_loss: 0.5239\n",
      "Epoch 443/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7488 - val_loss: 0.5235\n",
      "Epoch 444/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7481 - val_loss: 0.5231\n",
      "Epoch 445/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.7474 - val_loss: 0.5227\n",
      "Epoch 446/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.7466 - val_loss: 0.5223\n",
      "Epoch 447/500\n",
      "155/155 [==============================] - 0s 1ms/step - loss: 0.7459 - val_loss: 0.5219\n",
      "Epoch 448/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7452 - val_loss: 0.5216\n",
      "Epoch 449/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7445 - val_loss: 0.5212\n",
      "Epoch 450/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7437 - val_loss: 0.5208\n",
      "Epoch 451/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7430 - val_loss: 0.5204\n",
      "Epoch 452/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7423 - val_loss: 0.5200\n",
      "Epoch 453/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7416 - val_loss: 0.5196\n",
      "Epoch 454/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7409 - val_loss: 0.5192\n",
      "Epoch 455/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7402 - val_loss: 0.5188\n",
      "Epoch 456/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7394 - val_loss: 0.5185\n",
      "Epoch 457/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7387 - val_loss: 0.5181\n",
      "Epoch 458/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7379 - val_loss: 0.5177\n",
      "Epoch 459/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7372 - val_loss: 0.5173\n",
      "Epoch 460/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7365 - val_loss: 0.5169\n",
      "Epoch 461/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7357 - val_loss: 0.5165\n",
      "Epoch 462/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7350 - val_loss: 0.5161\n",
      "Epoch 463/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7343 - val_loss: 0.5157\n",
      "Epoch 464/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7335 - val_loss: 0.5153\n",
      "Epoch 465/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7328 - val_loss: 0.5149\n",
      "Epoch 466/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7320 - val_loss: 0.5145\n",
      "Epoch 467/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7313 - val_loss: 0.5141\n",
      "Epoch 468/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7306 - val_loss: 0.5137\n",
      "Epoch 469/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7298 - val_loss: 0.5133\n",
      "Epoch 470/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7291 - val_loss: 0.5129\n",
      "Epoch 471/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7284 - val_loss: 0.5126\n",
      "Epoch 472/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7277 - val_loss: 0.5122\n",
      "Epoch 473/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7270 - val_loss: 0.5118\n",
      "Epoch 474/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7263 - val_loss: 0.5114\n",
      "Epoch 475/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7255 - val_loss: 0.5110\n",
      "Epoch 476/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7248 - val_loss: 0.5106\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7241 - val_loss: 0.5102\n",
      "Epoch 478/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7234 - val_loss: 0.5098\n",
      "Epoch 479/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7227 - val_loss: 0.5094\n",
      "Epoch 480/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.5090\n",
      "Epoch 481/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7212 - val_loss: 0.5086\n",
      "Epoch 482/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7205 - val_loss: 0.5082\n",
      "Epoch 483/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7198 - val_loss: 0.5078\n",
      "Epoch 484/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7190 - val_loss: 0.5074\n",
      "Epoch 485/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7183 - val_loss: 0.5070\n",
      "Epoch 486/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7176 - val_loss: 0.5066\n",
      "Epoch 487/500\n",
      "155/155 [==============================] - 0s 3ms/step - loss: 0.7168 - val_loss: 0.5062\n",
      "Epoch 488/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7161 - val_loss: 0.5058\n",
      "Epoch 489/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7154 - val_loss: 0.5054\n",
      "Epoch 490/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7147 - val_loss: 0.5051\n",
      "Epoch 491/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7140 - val_loss: 0.5047\n",
      "Epoch 492/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7133 - val_loss: 0.5043\n",
      "Epoch 493/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7126 - val_loss: 0.5039\n",
      "Epoch 494/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7119 - val_loss: 0.5035\n",
      "Epoch 495/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7112 - val_loss: 0.5031\n",
      "Epoch 496/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7105 - val_loss: 0.5027\n",
      "Epoch 497/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7098 - val_loss: 0.5024\n",
      "Epoch 498/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7091 - val_loss: 0.5020\n",
      "Epoch 499/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7084 - val_loss: 0.5016\n",
      "Epoch 500/500\n",
      "155/155 [==============================] - 0s 2ms/step - loss: 0.7077 - val_loss: 0.5013\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4de88",
   "metadata": {},
   "source": [
    "# Plotting the Graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57936365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_on_trained = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c52297",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_predictions\u001b[49m(preds_on_untrained, preds_on_trained, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compare_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "compare_predictions(preds_on_untrained, preds_on_trained, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c3d46",
   "metadata": {},
   "source": [
    "# Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19014369",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_label_actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m price_on_untrained \u001b[38;5;241m=\u001b[39m [convert_label_actual(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m preds_on_untrained]\n\u001b[0;32m      2\u001b[0m price_on_trained \u001b[38;5;241m=\u001b[39m [convert_label_actual(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m preds_on_trained]\n\u001b[0;32m      3\u001b[0m price_y_test \u001b[38;5;241m=\u001b[39m [convert_label_actual(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m y_test]\n",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m price_on_untrained \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_label_actual\u001b[49m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m preds_on_untrained]\n\u001b[0;32m      2\u001b[0m price_on_trained \u001b[38;5;241m=\u001b[39m [convert_label_actual(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m preds_on_trained]\n\u001b[0;32m      3\u001b[0m price_y_test \u001b[38;5;241m=\u001b[39m [convert_label_actual(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m y_test]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_label_actual' is not defined"
     ]
    }
   ],
   "source": [
    "price_on_untrained = [convert_label_actual(y) for y in preds_on_untrained]\n",
    "price_on_trained = [convert_label_actual(y) for y in preds_on_trained]\n",
    "price_y_test = [convert_label_actual(y) for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77f1dd14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compare_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_predictions\u001b[49m(price_on_untrained, price_on_trained, price_y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compare_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "compare_predictions(price_on_untrained, price_on_trained, price_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
